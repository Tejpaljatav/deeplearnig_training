# -*- coding: utf-8 -*-
"""pre_ann.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DEEIrCBGrQ3L78AK1VrZBn5yjuMyTo0V
"""

import tensorflow as tf
from tensorflow import keras
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statistics as sts
import math
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report

data = pd.read_csv("/content/drive/MyDrive/customer_churn (1).csv")



data.head()

data.info()

data = data.drop("customerID", axis = 1)

data

data.info()

data.TotalCharges.unique()

np.str

data[data['TotalCharges']==" "]

data['TotalCharges'] = data['TotalCharges'].replace({' ': 0})

data.TotalCharges = pd.to_numeric(data.TotalCharges)   # convert object to int or float

data.info()

data[data.Churn == "Yes"].shape

data[data.Churn == "No"].shape



tenure_churn_no = data[data.Churn == "No"].tenure
tenure_churn_yes = data[data.Churn == "Yes"].tenure

plt.xlabel('Tenure')
plt.ylabel('Number of cust churned')
plt.title('Tenure v/s Number of cust churned')

plt.hist([tenure_churn_no, tenure_churn_yes], color = ['green', 'red'])
plt.legend()

SeniorCitizen_churn_no = data[data.Churn == "No"].SeniorCitizen
SeniorCitizen_churn_yes = data[data.Churn == "Yes"].SeniorCitizen

plt.xlabel('SeniorCitizen')
plt.ylabel('Number of cust churned')
plt.title('SeniorCitizen v/s Number of cust churned')

plt.hist([SeniorCitizen_churn_no, SeniorCitizen_churn_yes], color = ['green', 'red'])
plt.legend()

x = tenure_churn_no.count()
y = tenure_churn_yes.count()
a = np.array([x,y])
mylabels = ['tenure_churn_no','tenure_churn_yes']

plt.pie(a, labels = mylabels)

data.head()

data['Churn'] = data['Churn'].replace({'No': 0 , 'Yes': 1})

def co(d):
  for i in d:
    print(i,':',d[i].unique())

co(data)

# prompt: replace 'No phone service' and 'No internet service'  into 'No' in all coloumn


data['MultipleLines'] = data['MultipleLines'].replace({'No phone service': 'No'})
data['OnlineSecurity'] = data['OnlineSecurity'].replace({'No internet service': 'No'})
data['OnlineBackup'] = data['OnlineBackup'].replace({'No internet service': 'No'})
data['DeviceProtection'] = data['DeviceProtection'].replace({'No internet service': 'No'})
data['TechSupport'] = data['TechSupport'].replace({'No internet service': 'No'})
data['StreamingTV'] = data['StreamingTV'].replace({'No internet service': 'No'})
data['StreamingMovies'] = data['StreamingMovies'].replace({'No internet service': 'No'})

co(data)

# prompt: use getdummie function 'Internetservice', 'Contract' and 'PaymentMethod'

data = pd.get_dummies(data, columns = ['InternetService','Contract','PaymentMethod'])

co(data)

encoder = LabelEncoder()
data['gender'] = encoder.fit_transform(data['gender'])
data['Partner'] = encoder.fit_transform(data['Partner'])
data['Dependents'] = encoder.fit_transform(data['Dependents'])
data['PhoneService'] = encoder.fit_transform(data['PhoneService'])
data['MultipleLines'] = encoder.fit_transform(data['MultipleLines'])

data['OnlineSecurity'] = encoder.fit_transform(data['OnlineSecurity'])
data['OnlineBackup'] = encoder.fit_transform(data['OnlineBackup'])
data['DeviceProtection'] = encoder.fit_transform(data['DeviceProtection'])
data['StreamingTV'] = encoder.fit_transform(data['StreamingTV'])
data['StreamingMovies'] = encoder.fit_transform(data['StreamingMovies'])

data['PaperlessBilling'] = encoder.fit_transform(data['PaperlessBilling'])

data['TechSupport'] = encoder.fit_transform(data['TechSupport'])

co(data)

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
data[['tenure', 'MonthlyCharges', 'TotalCharges']] = scaler.fit_transform(data[['tenure', 'MonthlyCharges', 'TotalCharges']])
data.head()

co(data)

X = data.drop('Churn', axis = 1)
y = data['Churn']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)

y_train

model = keras.Sequential([keras.layers.Flatten(),
    keras.layers.Dense(64, input_shape = (26,), activation = "sigmoid"),
                            keras.layers.Dense(128, activation = "sigmoid"),
                            keras.layers.Dense(128, activation = "sigmoid"),
                            keras.layers.Dense(64, activation = 'sigmoid'),
                            keras.layers.Dense(32, activation = "sigmoid"),
                            keras.layers.Dense(2, activation = "sigmoid")])

model.compile(optimizer = "adam", loss = "sparse_categorical_crossentropy", metrics = ["accuracy"])

model.fit(X_train, y_train, epochs = 200)

# prompt: apply ANN

model.evaluate(X_test, y_test)

y_test_pre = model.predict(X_test)

df = []
for i in y_test_pre:
     x =(np.argmax(i))
     df.append(x)

y_pre = np.array(df)



cm = tf.math.confusion_matrix(y_test, y_pre)
type(cm)

cm

print(classification_report(y_test, y_pre))

plt.figure(figsize = (5,5))
sns.heatmap(cm, annot = True, fmt = "d")
plt.xlabel('Predict')
plt.ylabel('True')
plt.legend()

"""                     REMOVE VANISHING OR EXPLODING GREDIENT PROBLEM"""

model1 = keras.Sequential([keras.layers.Flatten(),
    keras.layers.Dense(64, input_shape = (26,), activation = "sigmoid",kernel_initializer = keras.initializers.GlorotNormal()),
                            keras.layers.Dense(128, activation = "sigmoid"),
                            keras.layers.Dense(128, activation = "sigmoid"),
                            keras.layers.Dense(64, activation = 'sigmoid'),
                            keras.layers.Dense(32, activation = "sigmoid"),
                            keras.layers.Dense(2, activation = "sigmoid")])

model1.compile(optimizer = "adam", loss = "sparse_categorical_crossentropy", metrics = ["accuracy"])

model1.fit(X_train, y_train, epochs = 200)

# prompt: add dropout layers in model1

model2 = keras.Sequential([keras.layers.Flatten(),
    keras.layers.Dense(64, input_shape = (26,), activation = "sigmoid",kernel_initializer = keras.initializers.GlorotNormal()),
    keras.layers.Dropout(0.2),
                            keras.layers.Dense(128, activation = "sigmoid"),
    keras.layers.Dropout(0.2),
                            keras.layers.Dense(128, activation = "sigmoid"),
    keras.layers.Dropout(0.2),
                            keras.layers.Dense(64, activation = 'sigmoid'),
    keras.layers.Dropout(0.2),
                            keras.layers.Dense(32, activation = "sigmoid"),
    keras.layers.Dropout(0.2),
                            keras.layers.Dense(2, activation = "sigmoid")])

model2.compile(optimizer = "adam", loss = "sparse_categorical_crossentropy", metrics = ["accuracy"])

model2.fit(X_train, y_train, epochs = 100)

# prompt: add batch normalization in model2

model3 = keras.Sequential([keras.layers.Flatten(),
    keras.layers.Dense(64, input_shape = (26,), activation = "sigmoid",kernel_initializer = keras.initializers.GlorotNormal()),
    keras.layers.BatchNormalization(),
    keras.layers.Dropout(0.2),
                            keras.layers.Dense(128, activation = "sigmoid"),
    keras.layers.BatchNormalization(),
    keras.layers.Dropout(0.2),
                            keras.layers.Dense(128, activation = "sigmoid"),
    keras.layers.BatchNormalization(),
    keras.layers.Dropout(0.2),
                            keras.layers.Dense(64, activation = 'sigmoid'),
    keras.layers.BatchNormalization(),
    keras.layers.Dropout(0.2),
                            keras.layers.Dense(32, activation = "sigmoid"),
    keras.layers.BatchNormalization(),
    keras.layers.Dropout(0.2),
                            keras.layers.Dense(2, activation = "sigmoid")])

model3.compile(optimizer = "adam", loss = "sparse_categorical_crossentropy", metrics = ["accuracy"])

model3.fit(X_train, y_train, epochs = 100)

model3.summary()

#  another way to write activation fuction in layer

model4 = keras.Sequential([keras.layers.Flatten(),
                           keras.layers.Dense(64, input_shape = (26,),kernel_initializer = keras.initializers.GlorotNormal()),
                           keras.layers.BatchNormalization(),
                           keras.layers.Activation('relu'),
                            keras.layers.Dense(2, activation = "sigmoid")])

model4.compile(optimizer = keras.optimizers.Adam(learning_rate = 0.01), loss = "sparse_categorical_crossentropy", metrics = ["accuracy"])

model4.fit(X_train, y_train, epochs = 100)

